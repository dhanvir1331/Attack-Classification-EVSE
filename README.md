# âš¡ EVSE Cyberattack Detection using ML & DL ğŸš—ğŸ”’

A full-scale machine learning and deep learning pipeline for detecting cyberattacks on **Electric Vehicle Supply Equipment (EVSE)** systems. This project showcases feature selection, preprocessing, classical ML models, PCA, DL architectures (CNN, ResNet, etc.), transfer learning, and comparative evaluation â€” all on a real-world dataset.

---

## ğŸ“‚ Table of Contents

- [ğŸ“– Project Description](#-project-description)
- [ğŸ“Š Dataset Overview](#-dataset-overview)
- [ğŸ”§ Project Architecture](#-project-architecture)
- [ğŸ“ˆ Models Implemented](#-models-implemented)
- [ğŸ” Feature Engineering](#-feature-engineering)
- [ğŸ‹ï¸ Model Training & Evaluation](#-model-training--evaluation)
- [ğŸ“Š Visualization Dashboard](#-visualization-dashboard)
- [ğŸš€ Results & Insights](#-results--insights)
- [ğŸ’¡ Future Work](#-future-work)
- [ğŸ“š References](#-references)

---

## ğŸ“– Project Description

With the rise of **smart mobility infrastructure**, EV charging stations are becoming critical components of modern power grids. However, they are increasingly vulnerable to **cyberattacks**, including DDoS, spoofing, and interface manipulation.

This project builds a **robust classification system** using both classical and deep learning approaches to:
- Detect cyberattacks vs. benign activity
- Interpret features using Point-Biserial correlation
- Optimize model performance with PCA and transfer learning
- Visualize performance and decision boundaries

---

## ğŸ“Š Dataset Overview

- ğŸ“ **File**: `EVSE-B-HPC-Kernel-Events-Combined.csv`
- ğŸ”¢ **Samples**: ~100,000+
- ğŸ·ï¸ **Classes**: `Label = 0 (Benign), 1 (Attack)`
- ğŸ“ **Features**: 800+ including CPU counters, memory metrics, I/O loads, system calls, etc.
- ğŸ§¹ **Cleaned**: Removed low-variance features and handled nulls with intelligent strategies

---

## ğŸ”§ Project Architecture

```bash
ğŸ“¦ EVSE_Cybersecurity_Detector
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ Cleaned_EVSE_Data.csv
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â””â”€â”€ Final_EVSE_attack_classification_nb.ipynb
â”œâ”€â”€ ğŸ“Š plots/
â”‚   â””â”€â”€ model_comparison.png
â”œâ”€â”€ ğŸ“„ README.md
```

---

## ğŸ“ˆ Models Implemented

### ğŸ§  Classical ML Models
- âœ… Logistic Regression
- ğŸŒ³ Random Forest
- ğŸ§® Support Vector Machine (SVM)
- ğŸ‘¥ K-Nearest Neighbors
- âš¡ XGBoost

### ğŸ¤– Deep Learning Models
- ğŸ§± Basic ANN
- ğŸŒ€ CNN (Shallow & Deep)
- ğŸ” LSTM (Optional)
- ğŸ—ï¸ ResNet-style Network
- ğŸ§  Transfer Learning with MobileNetV2

---

## ğŸ” Feature Engineering

- âœ… Removed low-information numeric features (low variance or <3 unique values)
- ğŸ”¢ Applied `StandardScaler` to normalize inputs
- ğŸ“‰ Applied PCA (`n_components=0.78`) to retain ~78% variance and reduce noise
- ğŸ“Š Used **Point-Biserial Correlation** to select statistically impactful features

---

## ğŸ‹ï¸ Model Training & Evaluation

Each model was:
- Trained on an 80-20 stratified split
- Validated using classification metrics:
  - Accuracy
  - Precision, Recall, F1-Score (Per Class)
  - Confusion Matrix
- For DL models:
  - Early Stopping
  - Dropout Regularization
  - L2 penalty
  - Epoch-wise tracking for training vs validation

---

## ğŸ“Š Visualization Dashboard

- âœ… Confusion matrices for every model
- ğŸ“ˆ Accuracy vs Epochs (for DL)
- ğŸ“‰ Loss curves
- ğŸ“Š Side-by-side bar plots for:
  - Accuracy
  - Precision / Recall / F1 per class
- ğŸ” ML vs DL comparative charts

![ML vs DL](plots/model_comparison.png)

---

## ğŸš€ Results & Insights

| Model               | Accuracy | Precision (1) | Recall (1) | F1 (1) |
|---------------------|----------|----------------|------------|--------|
| Logistic Regression | 87.93%   | 93%            | 88%        | 90%    |
| Random Forest       | 98.14%   | 98%            | 99%        | 99%    |
| SVM                 | 95.71%   | 98%            | 95%        | 97%    |
| KNN                 | 98.46%   | 99%            | 99%        | 99%    |
| XGBoost             | 98.38%   | 99%            | 98%        | 99%    |
| **CNN (Deep)**      | 97.50%   | 99%            | 98%        | 99%    |
| **Transfer (TF)**   | **98.80%** | **99%**        | **99%**    | **99%** |

âœ… **Transfer Learning with MobileNetV2** provided the best generalization on unseen data.

---

## ğŸ’¡ Future Work

- âš¡ Deploy model in edge devices or Raspberry Pi
- ğŸ” Build an online intrusion detection dashboard
- ğŸ“¦ Automate real-time streaming data classification
- ğŸ¯ Use attention-based transformers to detect complex temporal patterns
- ğŸ” Interpretability using SHAP or LIME

---

## ğŸ“š References

- [Point-Biserial Correlation â€” SciPy Docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pointbiserialr.html)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Keras Transfer Learning Guide](https://keras.io/guides/transfer_learning/)
- EVSE Cybersecurity Research Papers and Datasets (Anonymized source)

---

> _"Cybersecurity in EVs is not optionalâ€”it's foundational."_  
> â€” This project is a step toward building trustworthy transportation infrastructure.
